import { STTProvider } from "./stt-provider.interface";
import OpenAI from "openai";
import { Readable } from "stream";

interface OpenAIWhisperConfig {
  apiKey: string;
  model?: string;
  language?: string;
  prompt?: string;
  temperature?: number;
  responseFormat?: "json" | "text" | "srt" | "verbose_json" | "vtt";
}

export class OpenAIWhisperClient extends STTProvider {
  private config: OpenAIWhisperConfig;
  private openai: OpenAI;
  private audioBuffer: Buffer[] = [];
  private processingInterval: NodeJS.Timeout | null = null;
  private isProcessing: boolean = false;
  private lastProcessTime: number = 0;
  private minChunkDuration: number = 2000; // ÏµúÏÜå 2Ï¥à Î∂ÑÎüâÏùò Ïò§ÎîîÏò§ Î™®ÏïÑÏÑú Ï†ÑÏÜ°
  private sampleRate: number = 24000; // 24kHz
  private bytesPerSample: number = 2; // 16-bit PCM
  private lastTranscript: string = "";
  private transcriptBuffer: string[] = [];

  constructor(roomId: string, config: OpenAIWhisperConfig) {
    super(roomId);
    this.config = {
      model: "whisper-1",
      language: "ko",
      responseFormat: "verbose_json",
      temperature: 0,
      ...config,
    };
    this.openai = new OpenAI({ apiKey: this.config.apiKey });
  }

  async connect(): Promise<void> {
    console.log(`[STT][${this.roomId}] Connecting to OpenAI Whisper API...`);
    this.isConnected = true;
    this.lastProcessTime = Date.now();

    // Ï£ºÍ∏∞Ï†ÅÏúºÎ°ú Î≤ÑÌçº Ï≤òÎ¶¨ (1Ï¥àÎßàÎã§ Ï≤¥ÌÅ¨)
    this.processingInterval = setInterval(() => {
      this.checkAndProcessBuffer();
    }, 1000);

    this.emit("connected");
    console.log(`[STT][${this.roomId}] Connected to OpenAI Whisper API`);
  }

  private async checkAndProcessBuffer(): Promise<void> {
    if (this.isProcessing || this.audioBuffer.length === 0) {
      return;
    }

    const now = Date.now();
    const timeSinceLastProcess = now - this.lastProcessTime;
    const bufferBytes = this.audioBuffer.reduce((sum, buf) => sum + buf.length, 0);
    const bufferDuration = (bufferBytes / (this.sampleRate * this.bytesPerSample)) * 1000;

    // ÏµúÏÜå Ï≤≠ÌÅ¨ ÏãúÍ∞Ñ ÎòêÎäî 5Ï¥à Í≤ΩÍ≥º Ïãú Ï≤òÎ¶¨
    if (bufferDuration >= this.minChunkDuration || timeSinceLastProcess >= 5000) {
      await this.processAudioBuffer();
    }
  }

  private async processAudioBuffer(): Promise<void> {
    if (this.audioBuffer.length === 0 || this.isProcessing) {
      return;
    }

    this.isProcessing = true;
    const audioData = Buffer.concat(this.audioBuffer);
    this.audioBuffer = [];
    this.lastProcessTime = Date.now();

    try {
      console.log(`[STT][${this.roomId}] üì§ Processing ${audioData.length} bytes with Whisper API...`);

      // PCM Îç∞Ïù¥ÌÑ∞Î•º WAV ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò
      const wavBuffer = this.pcmToWav(audioData, this.sampleRate, this.bytesPerSample);

      // BlobÏúºÎ°ú Î≥ÄÌôòÌïòÏó¨ File Í∞ùÏ≤¥ ÏÉùÏÑ±
      const audioFile = new File([wavBuffer], "audio.wav", { type: "audio/wav" });

      // Whisper API Ìò∏Ï∂ú
      const startTime = Date.now();
      const response = await this.openai.audio.transcriptions.create({
        file: audioFile,
        model: this.config.model!,
        language: this.config.language,
        prompt: this.config.prompt,
        temperature: this.config.temperature,
        response_format: this.config.responseFormat,
      });

      const latency = Date.now() - startTime;

      // ÏùëÎãµ Ï≤òÎ¶¨
      let text = "";
      if (typeof response === "string") {
        text = response.trim();
      } else if ("text" in response) {
        text = response.text.trim();
      }

      if (text && text !== this.lastTranscript) {
        console.log(`[STT][${this.roomId}] ‚ö° Whisper latency: ${latency}ms | Text: "${text.substring(0, 50)}${text.length > 50 ? "..." : ""}"`);

        this.lastTranscript = text;
        this.transcriptBuffer.push(text);

        this.emit("transcript", {
          text,
          confidence: 1.0,
          final: true,
        });
      }
    } catch (error: any) {
      console.error(`[STT][${this.roomId}] Whisper API error:`, error?.message || error);
      this.emit("error", error);
    } finally {
      this.isProcessing = false;
    }
  }

  private pcmToWav(pcmData: Buffer, sampleRate: number, bytesPerSample: number): Buffer {
    const numChannels = 1; // Mono
    const bitsPerSample = bytesPerSample * 8;
    const byteRate = sampleRate * numChannels * bytesPerSample;
    const blockAlign = numChannels * bytesPerSample;
    const dataSize = pcmData.length;
    const headerSize = 44;

    const buffer = Buffer.alloc(headerSize + dataSize);

    // WAV Ìó§Îçî ÏûëÏÑ±
    buffer.write("RIFF", 0);
    buffer.writeUInt32LE(36 + dataSize, 4);
    buffer.write("WAVE", 8);
    buffer.write("fmt ", 12);
    buffer.writeUInt32LE(16, 16); // fmt chunk size
    buffer.writeUInt16LE(1, 20); // Audio format (1 = PCM)
    buffer.writeUInt16LE(numChannels, 22);
    buffer.writeUInt32LE(sampleRate, 24);
    buffer.writeUInt32LE(byteRate, 28);
    buffer.writeUInt16LE(blockAlign, 32);
    buffer.writeUInt16LE(bitsPerSample, 34);
    buffer.write("data", 36);
    buffer.writeUInt32LE(dataSize, 40);

    // PCM Îç∞Ïù¥ÌÑ∞ Î≥µÏÇ¨
    pcmData.copy(buffer, headerSize);

    return buffer;
  }

  sendAudio(audioData: Buffer): void {
    if (!this.isConnected) {
      console.warn(`[STT][${this.roomId}] ‚ö†Ô∏è  Not connected, ignoring audio`);
      return;
    }

    this.audioBuffer.push(audioData);

    // Î≤ÑÌçºÍ∞Ä ÎÑàÎ¨¥ Ïª§ÏßÄÎ©¥ Ï≤òÎ¶¨
    const bufferBytes = this.audioBuffer.reduce((sum, buf) => sum + buf.length, 0);
    const bufferDuration = (bufferBytes / (this.sampleRate * this.bytesPerSample)) * 1000;

    if (bufferDuration >= 10000) {
      // 10Ï¥à Ïù¥ÏÉÅ Î™®Ïù¥Î©¥ Ï¶âÏãú Ï≤òÎ¶¨
      this.processAudioBuffer();
    }
  }

  endStream(): void {
    // ÎÇ®ÏùÄ Î≤ÑÌçº Ï≤òÎ¶¨
    if (this.audioBuffer.length > 0) {
      this.processAudioBuffer();
    }
  }

  disconnect(): void {
    console.log(`[STT][${this.roomId}] Disconnecting from OpenAI Whisper API...`);

    if (this.processingInterval) {
      clearInterval(this.processingInterval);
      this.processingInterval = null;
    }

    // ÎÇ®ÏùÄ Ïò§ÎîîÏò§ Ï≤òÎ¶¨
    if (this.audioBuffer.length > 0) {
      this.processAudioBuffer();
    }

    this.isConnected = false;
    this.audioBuffer = [];
    this.emit("disconnected");
  }

  isActive(): boolean {
    return this.isConnected;
  }

  getProviderName(): string {
    return "openai-whisper";
  }
}
